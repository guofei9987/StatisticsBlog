{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立神经网络\n",
    "## 1.准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data=np.linspace(-1,1,300).reshape(-1,1)\n",
    "noise=np.random.normal(0,0.05,x_data.shape)\n",
    "y_data=np.square(x_data)-0.5+noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 建立一个层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "    weights=tf.Variable(tf.random_normal((in_size,out_size)))\n",
    "    biases=tf.Variable(tf.zeros(shape=(1,out_size))+0.1) #因为bias初始最好不为0\n",
    "    wx_plus_b=tf.matmul(inputs,weights)+biases\n",
    "    if activation_function is None:\n",
    "        outputs=wx_plus_b\n",
    "    else:\n",
    "        outputs=activation_function(wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 建立所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=tf.placeholder(shape=(None,1),dtype=tf.float32)\n",
    "ys=tf.placeholder(shape=(None,1),dtype=tf.float32)\n",
    "layer_1=add_layer(xs,1,10,activation_function=tf.nn.relu)\n",
    "prediction=add_layer(layer_1,10,1,activation_function=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=[1]))\n",
    "train_step=tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00325003\n",
      "0.00310567\n",
      "0.00298206\n",
      "0.00288067\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(train_step,feed_dict={xs:x_data,ys:y_data})\n",
    "    if i%300==0:\n",
    "        print(sess.run(loss,feed_dict={xs:x_data,ys:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数\n",
    "#### 1.交叉熵\n",
    "$H(p,q)=-\\sum p(x)\\log q(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))\n",
    "# y_代表正确结果，y代表预测结果\n",
    "# tf.clip_by_value可以把张量中的数值限制在某个范围内,这里为了防止log0报错\n",
    "# reduce_mean:大概是求均值？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow对softmax+crossentropy进行了封装\n",
    "cross_entropy=tf.nn.softmax_cross_entropy_with_logits(y,y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.MSE\n",
    "$MSE(y,y')=\\dfrac{\\sum (y-y')^2}{n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse=tf.reduce_mean(tf.square(y_-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.自定义\n",
    "例如，预测销量时，多预测一个损失1元，少预测1个损失10元。  \n",
    "$Loss(y,y')=\\sum f(y_i,y_i')$,\n",
    "$f(x,y)=\\left\\{\\begin{array}{ccc}a(x-y)&x>y\\\\\n",
    "b(y-x)&x\\leq y\\end{array}\\right.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss=tf.reduce_sum(tf.select(tf.greater(v1,v2),(v1-v2)*a,(v2-v1)*b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 学习率\n",
    "decayed_learning_rate=learning_rate * decay_rate ** (global_step/decay_steps)\n",
    "```\n",
    "tf.train.exponential_decay# 指数下降法减小学习率\n",
    "learning_rate=tf.train.exponential_decay(0.01,global_step=10000,decay_steps=100,decay_rate=0.96,staircase=True)\n",
    "```\n",
    "staircase=True时，(global_step/decay_steps)会转化成整数，导致学习率阶梯下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 iteration(s): x1 is 4.000000, learning rate is 0.096000.\n",
      "After 11 iteration(s): x11 is 0.690561, learning rate is 0.063824.\n",
      "After 21 iteration(s): x21 is 0.222583, learning rate is 0.042432.\n",
      "After 31 iteration(s): x31 is 0.106405, learning rate is 0.028210.\n",
      "After 41 iteration(s): x41 is 0.065548, learning rate is 0.018755.\n",
      "After 51 iteration(s): x51 is 0.047625, learning rate is 0.012469.\n",
      "After 61 iteration(s): x61 is 0.038558, learning rate is 0.008290.\n",
      "After 71 iteration(s): x71 is 0.033523, learning rate is 0.005511.\n",
      "After 81 iteration(s): x81 is 0.030553, learning rate is 0.003664.\n",
      "After 91 iteration(s): x91 is 0.028727, learning rate is 0.002436.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "TRAINING_STEPS = 100\n",
    "global_step = tf.Variable(0)\n",
    "LEARNING_RATE = tf.train.exponential_decay(0.1, global_step, 1, 0.96, staircase=True)\n",
    "\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y, global_step=global_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        if i % 10 == 0:\n",
    "            LEARNING_RATE_value = sess.run(LEARNING_RATE)\n",
    "            x_value = sess.run(x)\n",
    "            print (\"After %s iteration(s): x%s is %f, learning rate is %f.\"% (i+1, i+1, x_value, LEARNING_RATE_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过拟合\n",
    "cost Function加上L1 正则化或L2正则化  \n",
    "其中L1正则化可以将某些参数变成0，从而使参数系数。  \n",
    "L2不会使参数系数  \n",
    "(原因参见lasso和ridge regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.square(y_-y))+tf.contrib.layers.l2_regularizer(alpha)(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 滑动平均\n",
    "\n",
    "#### 1. 定义变量及滑动平均类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "v1 = tf.Variable(0, dtype=tf.float32)\n",
    "step = tf.Variable(0, trainable=False)\n",
    "ema = tf.train.ExponentialMovingAverage(0.99, step)\n",
    "maintain_averages_op = ema.apply([v1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 查看不同迭代中变量取值的变化。\n",
    "$\\min (decay,\\dfrac{1+num_{updates}}{10+num_{updates}})$\n",
    "一般情况下，decay设定为一个非常接近1的数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "[5.0, 4.5]\n",
      "[10.0, 4.5549998]\n",
      "[10.0, 4.6094499]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # 初始化\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print (sess.run([v1, ema.average(v1)]))\n",
    "    \n",
    "    # 更新变量v1的取值\n",
    "    sess.run(tf.assign(v1, 5))\n",
    "    sess.run(maintain_averages_op)#decay=0.1\n",
    "    print (sess.run([v1, ema.average(v1)])) #0.1*0+0.9*5=4.5\n",
    "    \n",
    "    # 更新step和v1的取值\n",
    "    sess.run(tf.assign(step, 10000))  \n",
    "    sess.run(tf.assign(v1, 10))\n",
    "    sess.run(maintain_averages_op)#decay=0.99\n",
    "    print (sess.run([v1, ema.average(v1)]) )      \n",
    "    \n",
    "    # 更新一次v1的滑动平均值\n",
    "    sess.run(maintain_averages_op)\n",
    "    print (sess.run([v1, ema.average(v1)])) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加入collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_loss=tf.multiply(tf.nn.l2_loss(var),wl,name='weight_loss')#wl是L2_loss的系数\n",
    "tf.add_to_collection('losses',weight_loss)#加入一个collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正则化的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.add_n(tf.get_collection('losses'),name='total_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把entropy也加入'losses'使代码简洁一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.add_to_collection('losses',cross_entropy)\n",
    "tf.add_n(tf.get_collection('losses'),name='total_loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
